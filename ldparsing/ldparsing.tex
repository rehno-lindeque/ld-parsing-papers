\documentclass[envcountsame,runningheads]{llncs}
\usepackage{pscproc2}
%\usepackage{url}

%\usepackage{tikz}
%\usepackage{geometry}
%\geometry{a4paper}
%\usepackage{gcl}
%\usepackage{float}
%\usepackage{wrapfig}
\usepackage{proof}
\usepackage{amssymb}
%\usepackage{amsthm}
\usepackage{amsmath}


% This is the shorter version of the technical report on "left-to-right parsing with delayed reductions" for the Prague Stringology Conference
\begin{document}
\title{Left-to-right parsing with delayed reductions}
\author{Rehno Lindeque \and Derrick Kourie}
\institute{University of Pretoria\\
\email{research@rehno.lindeque.name}}
\maketitle

\begin{abstract}
In this paper we suggest the use of delayed actions for parsing context-free languages.
We develop tools to study and develop the semantics of a domain specific language for building parsers with delayed reductions.
An informal proof shows that a parser implemented using our semantics will perform in linear time with respect to the number of lexical tokens.
Finally a prototype parser generator is described, capable of automatically generating parsers for a subset of context-free grammars.
\end{abstract}

\begin{keywords}
LD parser, recursive-ascent parser, context-free grammar, parser generator, bottom-up parser, top-down parser, delayed reductions
\end{keywords}

\section{Introduction}

[todo]

The remainder of this paper will be structured as follows. 
The operational semantics for a small, domain specific instruction set is developed.
[todo]

%Previous methods have often looked at lookahead as an adhoc extension of the parsing mechanism.

%In LD parsing lookahead is seen as a natural consequence extending from the notion of top-down versus bottom-up parsing strategies.
% PERHAPS:  extending from the dual???? symmetric???? complimentary??? orthogonal??? notions of top-down versus bottom-up parsing strategies.
%forms an explicit part of the domain specific language.
%

%Our approach combines top-down and bottom-up parsing strategies in a way that look-ahead naturally forms part of the parsing method rather than as a adhock extension.
%...relaxes the coupling between the parser's recognition mechanism and its translation mechanism.
%...first by recognizing a distinction between the parser's recognition mechanism and its translation mechanism and then properly/formally/naturally/thoroughly integrating lookahead into the recognition mechanism.

%Other methods have attempted to combine top-down and bottom-up parsing strategies through left-corner parsing\cite{}. 
%However, these take an ad-hoc approach, searching for ...., 
%failing to fully consolidate the notion of lookahead with recognition.

%For this reason we have managed to achieve an algorithmic improvement in time complexity over previous methods.

%Unlike previous research in this area we have also turned to tools from programming language theory in order clarify the semantics of our approach,
%leading to a simple, intuitive understanding of how the parser works. (amenable to formal analysis) (This has lead us to define a domain specific language...)

\section{Delayed reductions}

Our parsing strategy is divided into two passes.
[todo]

\subsection{Operational semantics}

\begin{equation}
\infer{i, j \mapsto i+1, j+1}{input_i = a & actions_j = shift(a)} \tag{shift}
\end{equation}

\begin{equation}
\infer{parserstate \mapsto error}{input_i = a & actions_j = shift(b)} \tag{shift-error}
\end{equation}

\begin{equation}
\infer{i, j, lasttarget, callstack_l, l \mapsto i+1, A_{input_i}, A_{input_i}, j+1, l+1}{input_i \in A & actions_j = switch(A)} \tag{switch}
\end{equation}

\begin{equation}
\infer{parsestate \mapsto error}{input_i \notin A & actions_j = switch(A)} \tag{switch-error}
\end{equation}

\begin{equation}
\infer{j, rulesbu\!f\!f\!er_k, k \mapsto j+1, r, k+1}{actions_j = reduce(r)} \tag{reduce}
\end{equation}

\begin{equation}
\infer{delays_m, m, j, rulesbu\!f\!f\!er_k, k \mapsto k, m+1, j+1, ignore, k+1}{actions_j = delay} \tag{delay}
\end{equation}

\begin{equation}
\infer{l, j, rulesbu\!f\!f\!er_{delays_{m-1}}, m \mapsto l-1, j+1, r, m-1}{actions_j = resolve(r)} \tag{resolve}
\end{equation}

\begin{equation}
\infer{j, l \mapsto callstack_{l-1}, l-1}{actions_j = return} \tag{return}
\end{equation}

\begin{equation}
\infer{j \mapsto A_{lasttarget}}{lasttarget \in A & actions_j = goto(A)} \tag{goto}
\end{equation}

\subsection{Trace semantics}

In order to translate a given string into a concrete syntax tree an LR parser must perform a sequence of $shi\!ft$ and $reduce$ operations.
For a given grammar $G$ we can mechanically generate a \emph{trace} of this sequence of operations on any string in the language $\boldsymbol{L}(G)$.
Restricting the traces to $shi\!ft$ and $reduce$ operations in an LR parser allows us to study the desired semantics of the parser independent of its lookahead mechanism, an orthogonal concern.
As most grammars of interest generate languages containing infinite sets of strings, the corresponding parsers will also generate an infinite set of traces, $traces(G)$.
Clearly the set of traces that a concrete $LR(k)$ parser with fixed lookahead $k$ can generate is restricted in the same way that the set of strings it can translate is restricted.
If we can construct an $LR(k)$ parser of finite length where $k$ is specified\footnote{The constraint that $k$ must be specified is important because finding such a $k$ automatically is undecidable in general.}
then $G$ will fall in the class of $LR(k)$ grammars.
It is not \emph{generally} possible to determine whether all the strings generated by a grammar can be parsed by a LD parser\footnote{In other words no algorithm exists to test whether a grammmar falls in a class of $LD$ grammars.}.
None-the-less, we wish to show that it is indeed possible to construct LD parsers of finite length for a broad class of grammars that include all $LR(k)$ grammars for any fixed value of $k$.

%If we can show that the set of traces a concrete LD parser will generate is equivalent to the set of traces generated by a theoretical LR parser then those parsers have the same strength.

\subsubsection{Mechanically generating traces.}

The \emph{shift-reduce traces} of a grammar can be enumerated without implementing a concrete parser.
However, a naive algorithm may become `stuck' inside a subtrace and never explore all the branches of a grammar.

Suppose that $\top_{G} \equiv traces(G)$, the---potentialy infinite---set of all possible of traces for the grammar and $\bot_{G} \equiv \{ \langle \rangle \}$ is the set containing the empty trace.
Is there a function $E(G,n)$ such that the following relations will hold?
\begin{equation} \bot_{G} \sqsubseteq E(G, n) \sqsubseteq E(G, n+1) \sqsubseteq \top_{G} \end{equation}
and
\begin{equation} lim_{n \to \infty} E(G,n) = \top_{G} \end{equation}

Here $\sqsubseteq$ is defined as a total ordering on sets of traces such that
\begin{equation} A \sqsubset B \quad \Longleftrightarrow \quad A \subset B\end{equation}

In order to generate a trace continuously explores the entire grammar our procedure will expand its traces in a breadth-first manner.
Hence $E(g,n)$ is defined in terms of two other functions. $I(G,n)$ holds all of the \emph{incomplete} traces that are yet to be generated while $Expand$ generates a new set of \emph{completed} traces from these.
\begin{eqnarray}
E(G, 0)   & \equiv & \{ \langle \rangle \} \\
E(G, n+1) & \equiv & E(G, n) \cup Expand(I(G, n))
\end{eqnarray}

For example, consider the following grammar.
{\small\begin{align*}
G \equiv \quad & A_1 \rightarrow a\\
               & A_2 \rightarrow y C\\
               & B_1 \rightarrow b\\
               & B_2 \rightarrow y D\\
               & S_1 \rightarrow A \$\\
               & S_2 \rightarrow B \$
\end{align*}}
Note that every production rule has a \emph{rule number} subscript and $\$$ represents the \emph{end-of-stream} token.


\section{A prototype parser generator}

As it is not possible to determine whether a grammar will fall in a class of $LD$ grammars,
there is no way of implementing a parser generator that will report any invalid grammar.
However, we do have an intuitive notion of what a practical parser should look like.
Instead of arbitrarily restricting the lookahead that a parser can handle\footnote{...as is the case with $LR(k)$ parsers.},
we simply restrict the complexity of the generated parser.
Practically this simply means that some termination condition must be supplied to the parser generator such as an upper bound on the size of the parser.

\section{Results}

By mechanically generating traces for the following grammars we are able to show which can be parsed successfully. [todo]

\section{Conclusions}
An earlier technical report describing additional details of the parsing DSL and parser generator can be found in \cite{Lin11}.

%The one disadvantage of this approach is that an entire file must be loaded... (but virtual memory and manual sectioning can offset this disadvantage)

\section{Future work}

It remains to develop a generalized LD parser for all context-free grammars, including those with ambiguities. 
Such GLD parsers would be equivalent in strength to GLR parsers, however it is hoped that such
a development would demonstrate superior performance to previous methods.

\bibliographystyle{psc}
\bibliography{ldparsing}

\end{document}

